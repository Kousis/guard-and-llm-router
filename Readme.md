
## Project Phases
1. **Current Phase:** Gather Information About the Topic 
2. Create the First Implementation and Set Up Evaluation Process
3. Iterate Until Reaching Project Goals
4. Prepare, Deploy and Test the Solution at Scale


## Papers

### Routers

#### RouterBench: A Benchmark for Multi-LLM Routing Systems

https://arxiv.org/pdf/2403.12031
 
This paper introduces RouterBench, an evaluation framework designed to systematically assess the efficacy of LLM routing systems. It provides a comprehensive dataset comprising over 405,000 inference outcomes from representative LLMs to support the development of routing strategies


#### MasRouter: Learning to Route LLMs for Multi-Agent Systems 

https://arxiv.org/pdf/2502.11133 

This research introduces MasRouter, a solution for Multi-Agent System Routing (MASR) that integrates all components of MAS into a unified routing framework. The proposed system employs collaboration mode determination, role allocation, and LLM routing through a cascaded controller network to balance effectiveness and efficiency.


#### Universal Model Routing for Efficient LLM Inference

https://arxiv.org/pdf/2502.08773

This paper addresses the problem of dynamic routing, where new, previously unobserved LLMs are available at test time. The authors propose a new approach that relies on representing each LLM as a feature vector, derived based on predictions on a set of representative prompts, to facilitate efficient routing.


#### Doing More with Lessâ€”Implementing Routing Strategies in Large Language Model-Based Systems: An Extended Survey

https://arxiv.org/pdf/2502.00409

This survey explores key considerations for integrating routing into LLM-based systems, focusing on resource management, cost definition, and strategy selection. It offers a formalization of the problem, a taxonomy of existing approaches emphasizing relevance and resource efficiency, and a comparative analysis of these strategies in relation to industry practices. 


#### RouteLLM: Learning to Route LLMs with Preference Data 

https://arxiv.org/pdf/2406.18665

A research paper that addresses the challenge of balancing performance and cost when deploying Large Language Models (LLMs). The study introduces a framework for training router models capable of dynamically selecting between a stronger (more capable but expensive) and a weaker (less capable but cost-effective) LLM during inference. The primary goal is to optimize the trade-off between response quality and computational expense.


### Guardrails 
TBD
